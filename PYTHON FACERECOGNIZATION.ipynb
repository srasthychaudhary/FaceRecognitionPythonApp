{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_detector = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "def face_cropper(img):\n",
    "    gray_image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_detector.detectMultiScale(gray_image, 1.3,5)\n",
    "    if len(faces)==0:\n",
    "        return None\n",
    "    elif len(faces)>0 :\n",
    "        for (x1,y1,x2,y2) in faces:\n",
    "            cropped_face = img[y1:y1+y2 , x1:x1+x2]\n",
    "            break\n",
    "    return cropped_face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples Pictures Collected Successfully\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "cap = cv2.VideoCapture(0)\n",
    "count = 0\n",
    "abs_path = './collected_pictures/' # {.} current directr \n",
    "while True:\n",
    "    ret, photo = cap.read()\n",
    "    cropped_face = face_cropper(photo)\n",
    "    if cropped_face is not None:\n",
    "        cropped_face = cv2.resize(cropped_face, (200,200))\n",
    "        cropped_face = cv2.cvtColor(cropped_face, cv2.COLOR_BGR2GRAY)\n",
    "        count+=1\n",
    "        file_name = str(count)+'.jpg'\n",
    "        saved = cv2.imwrite(os.path.join(abs_path, file_name), cropped_face)\n",
    "        if not saved:\n",
    "            print(\"Couldn't Save your Photos!\")\n",
    "            \n",
    "            print(\"Make sure the folder with name 'collected_pictures' is created under current working directory\")\n",
    "            break\n",
    "        cv2.putText(cropped_face, str(count), (50,50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.imshow('Cropped Face', cropped_face)\n",
    "    else:\n",
    "        pass\n",
    "    if count==100:\n",
    "        print('Samples Pictures Collected Successfully')\n",
    "        break\n",
    "    if cv2.waitKey(10)==13:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Trained Successfully!\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "abs_path = './collected_pictures/'\n",
    "face_files = [f for f in listdir(abs_path) if isfile(join(abs_path, f))]\n",
    "train_data, labels=[], []\n",
    "for i,file_name in enumerate(face_files):\n",
    "    image_path = abs_path+face_files[i]\n",
    "    faceImg = Image.open(image_path)\n",
    "    train_data.append(np.array(faceImg, dtype=np.uint8))\n",
    "    labels.append(i)\n",
    "\n",
    "labels = np.asarray(labels, dtype=np.int32)\n",
    "\n",
    "model = cv2.face_LBPHFaceRecognizer.create()\n",
    "model.train(train_data, labels)\n",
    "print(\"Model Trained Successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_detector = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "def face_detect_crop(img):\n",
    "    gray_image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_detector.detectMultiScale(gray_image, 1.3,5)\n",
    "    if len(faces)==0:\n",
    "        return img, []\n",
    "    elif len(faces)>0 :\n",
    "        for (x1,y1,x2,y2) in faces:\n",
    "            img = cv2.rectangle(img, (x1,y1),(x1+x2,y1+y2), [255,255,255], 1)\n",
    "            cropped_face = img[y1:y1+y2 , x1:x1+x2]\n",
    "            cropped_face = cv2.resize(cropped_face, (200,200))\n",
    "    return img, cropped_face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init():\n",
    "    print(\"Output of 'terraform init' command :\")\n",
    "    print(subprocess.getoutput(\"terraform init\"))\n",
    "    print()\n",
    "    [print(\"-\",end='') for i in range(80)]\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply():\n",
    "    print(\"Output of 'terraform apply' command :\")\n",
    "    print(subprocess.getoutput(\"terraform apply -auto-approve\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import subprocess\n",
    "\n",
    "success = 0\n",
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    ret, photo = cap.read()\n",
    "    detected_image, cropped_face = face_detect_crop(photo)\n",
    "    try:\n",
    "        cropped_face = cv2.cvtColor(cropped_face, cv2.COLOR_BGR2GRAY)\n",
    "        result = model.predict(cropped_face)\n",
    "        if result[1]<500:\n",
    "            confidence = int(100*(1-((result[1])/400)))\n",
    "            display_string = 'Confidence : '+str(confidence)+'%'\n",
    "        cv2.putText(detected_image, display_string, (170,50), cv2.FONT_HERSHEY_COMPLEX, 1 ,(255,255,0), 2)\n",
    "        if confidence > 90:\n",
    "            cv2.putText(detected_image, \" Hello Friends !!!\", (230,450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "            cv2.imshow(\"Face Recognizer\", detected_image)\n",
    "            cv2.putText(detected_image, \"Launching Instance...\", (160, 350), cv2.FONT_HERSHEY_COMPLEX, 1, (255,255,255), 2)\n",
    "            cv2.imshow(\"Face Recognizer\", detected_image)    \n",
    "            cv2.waitKey(3000)\n",
    "            success=1\n",
    "            break\n",
    "        else:\n",
    "            cv2.putText(detected_image, \"Mismatch/Low Confidence\", (110,450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "            cv2.imshow(\"Face Recognizer\", detected_image)\n",
    "    except:\n",
    "        cv2.putText(detected_image, \"No Face Found\", (200,450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.imshow(\"Face Recognizer\", detected_image)\n",
    "        pass\n",
    "    if cv2.waitKey(10)==13:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "if success:\n",
    "    init()\n",
    "    apply()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
